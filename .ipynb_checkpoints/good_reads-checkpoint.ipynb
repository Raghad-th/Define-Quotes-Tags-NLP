{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as req\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "import os\n",
    "from random_user_agent.user_agent import UserAgent\n",
    "from random_user_agent.params import SoftwareName, OperatingSystem, SoftwareEngine, HardwareType, SoftwareType, Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url,parser):\n",
    "    \"\"\"\n",
    "    Download the html via request library,\n",
    "    Useing User Agent to avoid anti-scraer detiction \n",
    "    Using beautifulsoup to parse content\n",
    "    \n",
    "    Arguments\n",
    "    url for the target site \n",
    "    parser to be used to parse data('lxml','html','html5lib')\n",
    "    \n",
    "    return soup of html content\n",
    "    \n",
    "    \"\"\"\n",
    "    software_names = [SoftwareName.CHROME.value]\n",
    "    operating_systems = [OperatingSystem.WINDOWS.value, OperatingSystem.LINUX.value]   \n",
    "\n",
    "    user_agent_rotator = UserAgent(software_names=software_names, operating_systems=operating_systems, limit=10000)\n",
    "\n",
    "        # Get list of user agents.\n",
    "    user_agents = user_agent_rotator.get_user_agents()\n",
    "\n",
    "        # Get Random User Agent String.\n",
    "    user_agent = user_agent_rotator.get_random_user_agent()\n",
    "    headers = {'User-agent':user_agent}\n",
    "    if not os.path.exists('response'):\n",
    "        os.makedirs('response')\n",
    "    r = req.get(url, headers = headers)\n",
    "    with open ('response/response',mode = 'w', encoding = 'UTF-8') as file:\n",
    "        file.write(r.text)\n",
    "    with open ('response/response',mode = 'r', encoding = 'UTF-8') as file:\n",
    "        soup = bs(file,parser)\n",
    "    return(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(url):\n",
    "    soup = get_soup(url,'lxml')\n",
    "    category_list = soup.findAll('li', class_=\"greyText\")\n",
    "    cat_dic = {}\n",
    "    for i in range(len(category_list)):\n",
    "        category = category_list[i].text.split()[0]\n",
    "        link = category_list[i].a['href']\n",
    "        cat_dic[category] = main_link+link\n",
    "    return cat_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(soup):\n",
    "    quote_list = soup.findAll('div', attrs={'class':'quote'})\n",
    "    d={}\n",
    "    for q in quote_list:\n",
    "        try:\n",
    "            author = q.find('div',  attrs={'class':'quoteDetails'}).span.text.split('\\n')[1].strip()\n",
    "            text = q.find('div',  attrs={'class':'quoteDetails'}).find('div',  attrs={'class':'quoteText'}).text.split('\\n')[1].strip().replace('”','').replace('“','')\n",
    "        except:\n",
    "            print('FAILED')\n",
    "            continue\n",
    "        if author and text:\n",
    "            d ['quot'] = text\n",
    "            d ['author'] = author\n",
    "            d['category'] = category\n",
    "\n",
    "        with open(\"data.txt\", \"a\") as outfile:\n",
    "            json.dump(d, outfile)\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(file_name):\n",
    "    df_list = []\n",
    "    with open (file_name,\"r\") as j_file:\n",
    "        for l in j_file:\n",
    "            dic = {}\n",
    "            data=json.loads(l)\n",
    "            dic['quot'] = data['quot']\n",
    "            dic['author'] = data['author']\n",
    "            dic['category'] = data['category']\n",
    "            df_list.append(dic)\n",
    "    df = pd.DataFrame(df_list,columns = ['quot','author','category'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_link = 'https://www.goodreads.com'\n",
    "url = main_link + '/quotes'\n",
    "categories = get_categories(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love\n",
      "page 100\n",
      "Life\n",
      "page 100\n",
      "Inspirational\n",
      "page 100\n",
      "Humor\n",
      "page 100\n",
      "Philosophy\n",
      "page 100\n",
      "God\n",
      "page 100\n",
      "Truth\n",
      "page 100\n",
      "Wisdom\n",
      "page 100\n",
      "Poetry\n",
      "page 100\n",
      "Romance\n",
      "page 100\n",
      "Death\n",
      "page 100\n",
      "Happiness\n",
      "page 100\n",
      "Hope\n",
      "page 100\n",
      "Faith\n",
      "page 100\n",
      "Inspiration\n",
      "page 100\n",
      "Quotes\n",
      "page 100\n",
      "Writing\n",
      "page 100\n",
      "Religion\n",
      "page 100\n",
      "Motivational\n",
      "page 100\n",
      "Relationships\n",
      "page 100\n",
      "Success\n",
      "page 100\n",
      "Spirituality\n",
      "page 100\n",
      "Time\n",
      "page 100\n",
      "Knowledge\n",
      "page 100\n",
      "Science\n",
      "page 100\n",
      "Motivation\n",
      "page 100\n"
     ]
    }
   ],
   "source": [
    "for k ,v in categories.items():\n",
    "    url = v + '?page='\n",
    "    category = k\n",
    "    print(k)\n",
    "    for i in range(1,101):\n",
    "        print('page {}'.format(i))\n",
    "        page_url = url+str(i)\n",
    "        soup = get_soup(page_url, 'lxml')\n",
    "        get_data(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quot</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love you as certain dark things are loved, s...</td>\n",
       "      <td>Pablo Neruda,</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is an absolute human certainty that no one ...</td>\n",
       "      <td>John Joseph Powell,</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If I have learned anything in this long life o...</td>\n",
       "      <td>Kristin Hannah,</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>your handtouching mine.this is howgalaxiescoll...</td>\n",
       "      <td>Sanober Khan</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I choose to love you in silence…For in silence...</td>\n",
       "      <td>Rumi</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31675</th>\n",
       "      <td>The hours tick by as I lie in bed.Memories kee...</td>\n",
       "      <td>Ashley Earley,</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31676</th>\n",
       "      <td>Fuck the rules, Allie, he whispered. They were...</td>\n",
       "      <td>Mona Kasten,</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31677</th>\n",
       "      <td>He pulled me toward him, and all I could do wa...</td>\n",
       "      <td>Jodi LaPalm,</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31678</th>\n",
       "      <td>Perhaps, deep down inside that rugged shell of...</td>\n",
       "      <td>Sylvain Neuvel,</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31679</th>\n",
       "      <td>It occurred to her that all the bad parts of l...</td>\n",
       "      <td>Martina Boone,</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31680 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    quot               author  \\\n",
       "0      I love you as certain dark things are loved, s...        Pablo Neruda,   \n",
       "1      It is an absolute human certainty that no one ...  John Joseph Powell,   \n",
       "2      If I have learned anything in this long life o...      Kristin Hannah,   \n",
       "3      your handtouching mine.this is howgalaxiescoll...         Sanober Khan   \n",
       "4      I choose to love you in silence…For in silence...                 Rumi   \n",
       "...                                                  ...                  ...   \n",
       "31675  The hours tick by as I lie in bed.Memories kee...       Ashley Earley,   \n",
       "31676  Fuck the rules, Allie, he whispered. They were...         Mona Kasten,   \n",
       "31677  He pulled me toward him, and all I could do wa...         Jodi LaPalm,   \n",
       "31678  Perhaps, deep down inside that rugged shell of...      Sylvain Neuvel,   \n",
       "31679  It occurred to her that all the bad parts of l...       Martina Boone,   \n",
       "\n",
       "      category  \n",
       "0         Love  \n",
       "1         Love  \n",
       "2         Love  \n",
       "3         Love  \n",
       "4         Love  \n",
       "...        ...  \n",
       "31675  Romance  \n",
       "31676  Romance  \n",
       "31677  Romance  \n",
       "31678  Romance  \n",
       "31679  Romance  \n",
       "\n",
       "[31680 rows x 3 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_dataframe('data.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output file.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
